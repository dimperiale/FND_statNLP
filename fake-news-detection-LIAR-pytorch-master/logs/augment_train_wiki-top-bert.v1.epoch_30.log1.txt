features: augmented
feat_list: ['wiki_bert_feat']
Preparing data from: train2.tsv
fault: 0
  10269 samples
  Statement Vocabulary Size: 1
  Subject Vocabulary Size: 1
  Speaker Vocabulary Size: 1
  Speaker Position Vocabulary Size: 1
  State Vocabulary Size: 1
  Party Vocabulary Size: 1
  Context Vocabulary Size: 1
  Justification Vocabulary Size: 1
  Vocabulary Size: 54832
fault: 0
  Constructing network model...
Hyperparams are:
num_classes :  6
epoch :  30
lr :  0.001
embed_dim :  100
statement_kernel_num :  64
statement_kernel_size :  [3, 4, 5]
subject_hidden_dim :  8
subject_lstm_nlayers :  2
subject_lstm_bidirectional :  True
speaker_pos_hidden_dim :  8
speaker_pos_lstm_nlayers :  2
speaker_pos_lstm_bidirectional :  True
context_hidden_dim :  16
context_lstm_nlayers :  2
context_lstm_bidirectional :  True
justification_hidden_dim :  32
justification_lstm_nlayers :  2
justification_lstm_bidirectional :  True
dropout_query :  0.5
dropout_features :  0.7

  Start training
  [INFO] - Epoch 1/30 Step:: 500 Loss: 3.303
  [INFO] - Epoch 1/30 Step:: 1000 Loss: 2.784
  [INFO] - Epoch 1/30 Step:: 1500 Loss: 1.220
  [INFO] - Epoch 1/30 Step:: 2000 Loss: 1.794
  [INFO] - Epoch 1/30 Step:: 2500 Loss: 1.047
  [INFO] - Epoch 1/30 Step:: 3000 Loss: 0.906
  [INFO] - Epoch 1/30 Step:: 3500 Loss: 2.060
  [INFO] - Epoch 1/30 Step:: 4000 Loss: 2.246
  [INFO] - Epoch 1/30 Step:: 4500 Loss: 0.936
  [INFO] - Epoch 1/30 Step:: 5000 Loss: 1.977
  [INFO] - Epoch 1/30 Step:: 5500 Loss: 1.416
  [INFO] - Epoch 1/30 Step:: 6000 Loss: 0.678
  [INFO] - Epoch 1/30 Step:: 6500 Loss: 1.801
  [INFO] - Epoch 1/30 Step:: 7000 Loss: 3.370
  [INFO] - Epoch 1/30 Step:: 7500 Loss: 1.347
  [INFO] - Epoch 1/30 Step:: 8000 Loss: 3.315
  [INFO] - Epoch 1/30 Step:: 8500 Loss: 1.866
  [INFO] - Epoch 1/30 Step:: 9000 Loss: 2.681
  [INFO] - Epoch 1/30 Step:: 9500 Loss: 1.622
  [INFO] - Epoch 1/30 Step:: 10000 Loss: 0.567
  [INFO] --- Epoch 1 complete. Avg. Loss: 2.184  Time taken: 318.180
  Validation Accuracy: 0.220
Saved:  m-fake-nettime-2021_05_16_18_31_23--num_classes-6-16052021-182303-epoch-0-val_acc-0.220-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 2/30 Step:: 10500 Loss: 2.071
  [INFO] - Epoch 2/30 Step:: 11000 Loss: 2.287
  [INFO] - Epoch 2/30 Step:: 11500 Loss: 1.690
  [INFO] - Epoch 2/30 Step:: 12000 Loss: 2.501
  [INFO] - Epoch 2/30 Step:: 12500 Loss: 1.419
  [INFO] - Epoch 2/30 Step:: 13000 Loss: 2.742
  [INFO] - Epoch 2/30 Step:: 13500 Loss: 0.757
  [INFO] - Epoch 2/30 Step:: 14000 Loss: 3.531
  [INFO] - Epoch 2/30 Step:: 14500 Loss: 2.350
  [INFO] - Epoch 2/30 Step:: 15000 Loss: 2.760
  [INFO] - Epoch 2/30 Step:: 15500 Loss: 0.600
  [INFO] - Epoch 2/30 Step:: 16000 Loss: 4.310
  [INFO] - Epoch 2/30 Step:: 16500 Loss: 0.901
  [INFO] - Epoch 2/30 Step:: 17000 Loss: 2.781
  [INFO] - Epoch 2/30 Step:: 17500 Loss: 0.989
  [INFO] - Epoch 2/30 Step:: 18000 Loss: 2.901
  [INFO] - Epoch 2/30 Step:: 18500 Loss: 1.282
  [INFO] - Epoch 2/30 Step:: 19000 Loss: 3.335
  [INFO] - Epoch 2/30 Step:: 19500 Loss: 0.902
  [INFO] - Epoch 2/30 Step:: 20000 Loss: 2.669
  [INFO] - Epoch 2/30 Step:: 20500 Loss: 4.659
  [INFO] --- Epoch 2 complete. Avg. Loss: 2.142  Time taken: 655.151
  Validation Accuracy: 0.215
Saved:  m-fake-nettime-2021_05_16_18_37_00--num_classes-6-16052021-182303-epoch-1-val_acc-0.215-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 3/30 Step:: 21000 Loss: 1.686
  [INFO] - Epoch 3/30 Step:: 21500 Loss: 4.783
  [INFO] - Epoch 3/30 Step:: 22000 Loss: 1.738
  [INFO] - Epoch 3/30 Step:: 22500 Loss: 2.243
  [INFO] - Epoch 3/30 Step:: 23000 Loss: 2.192
  [INFO] - Epoch 3/30 Step:: 23500 Loss: 1.896
  [INFO] - Epoch 3/30 Step:: 24000 Loss: 1.047
  [INFO] - Epoch 3/30 Step:: 24500 Loss: 1.282
  [INFO] - Epoch 3/30 Step:: 25000 Loss: 1.317
  [INFO] - Epoch 3/30 Step:: 25500 Loss: 2.360
  [INFO] - Epoch 3/30 Step:: 26000 Loss: 1.542
  [INFO] - Epoch 3/30 Step:: 26500 Loss: 2.165
  [INFO] - Epoch 3/30 Step:: 27000 Loss: 1.725
  [INFO] - Epoch 3/30 Step:: 27500 Loss: 1.869
  [INFO] - Epoch 3/30 Step:: 28000 Loss: 1.745
  [INFO] - Epoch 3/30 Step:: 28500 Loss: 2.522
  [INFO] - Epoch 3/30 Step:: 29000 Loss: 1.342
  [INFO] - Epoch 3/30 Step:: 29500 Loss: 2.162
  [INFO] - Epoch 3/30 Step:: 30000 Loss: 3.472
  [INFO] - Epoch 3/30 Step:: 30500 Loss: 1.858
  [INFO] --- Epoch 3 complete. Avg. Loss: 2.102  Time taken: 954.791
  Validation Accuracy: 0.206
Saved:  m-fake-nettime-2021_05_16_18_41_59--num_classes-6-16052021-182303-epoch-2-val_acc-0.206-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 4/30 Step:: 31000 Loss: 3.407
  [INFO] - Epoch 4/30 Step:: 31500 Loss: 2.617
  [INFO] - Epoch 4/30 Step:: 32000 Loss: 2.213
  [INFO] - Epoch 4/30 Step:: 32500 Loss: 2.743
  [INFO] - Epoch 4/30 Step:: 33000 Loss: 3.248
  [INFO] - Epoch 4/30 Step:: 33500 Loss: 1.388
  [INFO] - Epoch 4/30 Step:: 34000 Loss: 2.592
  [INFO] - Epoch 4/30 Step:: 34500 Loss: 2.733
  [INFO] - Epoch 4/30 Step:: 35000 Loss: 6.547
  [INFO] - Epoch 4/30 Step:: 35500 Loss: 3.542
  [INFO] - Epoch 4/30 Step:: 36000 Loss: 3.397
  [INFO] - Epoch 4/30 Step:: 36500 Loss: 1.426
  [INFO] - Epoch 4/30 Step:: 37000 Loss: 1.826
  [INFO] - Epoch 4/30 Step:: 37500 Loss: 2.923
  [INFO] - Epoch 4/30 Step:: 38000 Loss: 0.986
  [INFO] - Epoch 4/30 Step:: 38500 Loss: 1.052
  [INFO] - Epoch 4/30 Step:: 39000 Loss: 2.112
  [INFO] - Epoch 4/30 Step:: 39500 Loss: 2.752
  [INFO] - Epoch 4/30 Step:: 40000 Loss: 2.403
  [INFO] - Epoch 4/30 Step:: 40500 Loss: 1.566
  [INFO] - Epoch 4/30 Step:: 41000 Loss: 1.730
  [INFO] --- Epoch 4 complete. Avg. Loss: 2.065  Time taken: 1282.750
  Validation Accuracy: 0.238
Saved:  m-fake-nettime-2021_05_16_18_47_27--num_classes-6-16052021-182303-epoch-3-val_acc-0.238-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 5/30 Step:: 41500 Loss: 2.844
  [INFO] - Epoch 5/30 Step:: 42000 Loss: 1.399
  [INFO] - Epoch 5/30 Step:: 42500 Loss: 0.375
  [INFO] - Epoch 5/30 Step:: 43000 Loss: 4.142
  [INFO] - Epoch 5/30 Step:: 43500 Loss: 1.700
  [INFO] - Epoch 5/30 Step:: 44000 Loss: 1.553
  [INFO] - Epoch 5/30 Step:: 44500 Loss: 3.495
  [INFO] - Epoch 5/30 Step:: 45000 Loss: 1.087
  [INFO] - Epoch 5/30 Step:: 45500 Loss: 2.514
  [INFO] - Epoch 5/30 Step:: 46000 Loss: 12.164
  [INFO] - Epoch 5/30 Step:: 46500 Loss: 0.806
  [INFO] - Epoch 5/30 Step:: 47000 Loss: 0.851
  [INFO] - Epoch 5/30 Step:: 47500 Loss: 0.905
  [INFO] - Epoch 5/30 Step:: 48000 Loss: 2.144
  [INFO] - Epoch 5/30 Step:: 48500 Loss: 1.191
  [INFO] - Epoch 5/30 Step:: 49000 Loss: 3.546
  [INFO] - Epoch 5/30 Step:: 49500 Loss: 1.696
  [INFO] - Epoch 5/30 Step:: 50000 Loss: 2.700
  [INFO] - Epoch 5/30 Step:: 50500 Loss: 1.834
  [INFO] - Epoch 5/30 Step:: 51000 Loss: 3.282
  [INFO] --- Epoch 5 complete. Avg. Loss: 2.053  Time taken: 1613.007
  Validation Accuracy: 0.225
Saved:  m-fake-nettime-2021_05_16_18_52_57--num_classes-6-16052021-182303-epoch-4-val_acc-0.225-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 6/30 Step:: 51500 Loss: 3.210
  [INFO] - Epoch 6/30 Step:: 52000 Loss: 1.012
  [INFO] - Epoch 6/30 Step:: 52500 Loss: 1.843
  [INFO] - Epoch 6/30 Step:: 53000 Loss: 1.007
  [INFO] - Epoch 6/30 Step:: 53500 Loss: 1.242
  [INFO] - Epoch 6/30 Step:: 54000 Loss: 4.429
  [INFO] - Epoch 6/30 Step:: 54500 Loss: 4.323
  [INFO] - Epoch 6/30 Step:: 55000 Loss: 2.769
  [INFO] - Epoch 6/30 Step:: 55500 Loss: 1.717
  [INFO] - Epoch 6/30 Step:: 56000 Loss: 0.877
  [INFO] - Epoch 6/30 Step:: 56500 Loss: 0.839
  [INFO] - Epoch 6/30 Step:: 57000 Loss: 2.014
  [INFO] - Epoch 6/30 Step:: 57500 Loss: 2.131
  [INFO] - Epoch 6/30 Step:: 58000 Loss: 2.705
  [INFO] - Epoch 6/30 Step:: 58500 Loss: 1.012
  [INFO] - Epoch 6/30 Step:: 59000 Loss: 2.011
  [INFO] - Epoch 6/30 Step:: 59500 Loss: 1.486
  [INFO] - Epoch 6/30 Step:: 60000 Loss: 3.489
  [INFO] - Epoch 6/30 Step:: 60500 Loss: 2.033
  [INFO] - Epoch 6/30 Step:: 61000 Loss: 3.197
  [INFO] - Epoch 6/30 Step:: 61500 Loss: 0.825
  [INFO] --- Epoch 6 complete. Avg. Loss: 2.027  Time taken: 1935.484
  Validation Accuracy: 0.219
Saved:  m-fake-nettime-2021_05_16_18_58_20--num_classes-6-16052021-182303-epoch-5-val_acc-0.219-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 7/30 Step:: 62000 Loss: 2.509
  [INFO] - Epoch 7/30 Step:: 62500 Loss: 1.855
  [INFO] - Epoch 7/30 Step:: 63000 Loss: 2.920
  [INFO] - Epoch 7/30 Step:: 63500 Loss: 2.727
  [INFO] - Epoch 7/30 Step:: 64000 Loss: 1.293
  [INFO] - Epoch 7/30 Step:: 64500 Loss: 0.834
  [INFO] - Epoch 7/30 Step:: 65000 Loss: 0.451
  [INFO] - Epoch 7/30 Step:: 65500 Loss: 0.814
  [INFO] - Epoch 7/30 Step:: 66000 Loss: 1.809
  [INFO] - Epoch 7/30 Step:: 66500 Loss: 1.104
  [INFO] - Epoch 7/30 Step:: 67000 Loss: 5.056
  [INFO] - Epoch 7/30 Step:: 67500 Loss: 1.084
  [INFO] - Epoch 7/30 Step:: 68000 Loss: 2.606
  [INFO] - Epoch 7/30 Step:: 68500 Loss: 3.716
  [INFO] - Epoch 7/30 Step:: 69000 Loss: 1.376
  [INFO] - Epoch 7/30 Step:: 69500 Loss: 2.151
  [INFO] - Epoch 7/30 Step:: 70000 Loss: 2.647
  [INFO] - Epoch 7/30 Step:: 70500 Loss: 1.694
  [INFO] - Epoch 7/30 Step:: 71000 Loss: 4.329
  [INFO] - Epoch 7/30 Step:: 71500 Loss: 2.537
  [INFO] --- Epoch 7 complete. Avg. Loss: 1.985  Time taken: 2240.109
  Validation Accuracy: 0.240
Saved:  m-fake-nettime-2021_05_16_19_03_25--num_classes-6-16052021-182303-epoch-6-val_acc-0.240-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 8/30 Step:: 72000 Loss: 2.086
  [INFO] - Epoch 8/30 Step:: 72500 Loss: 0.289
  [INFO] - Epoch 8/30 Step:: 73000 Loss: 1.302
  [INFO] - Epoch 8/30 Step:: 73500 Loss: 0.706
  [INFO] - Epoch 8/30 Step:: 74000 Loss: 2.839
  [INFO] - Epoch 8/30 Step:: 74500 Loss: 4.204
  [INFO] - Epoch 8/30 Step:: 75000 Loss: 2.159
  [INFO] - Epoch 8/30 Step:: 75500 Loss: 2.782
  [INFO] - Epoch 8/30 Step:: 76000 Loss: 2.370
  [INFO] - Epoch 8/30 Step:: 76500 Loss: 1.534
  [INFO] - Epoch 8/30 Step:: 77000 Loss: 1.755
  [INFO] - Epoch 8/30 Step:: 77500 Loss: 0.867
  [INFO] - Epoch 8/30 Step:: 78000 Loss: 0.807
  [INFO] - Epoch 8/30 Step:: 78500 Loss: 2.756
  [INFO] - Epoch 8/30 Step:: 79000 Loss: 0.975
  [INFO] - Epoch 8/30 Step:: 79500 Loss: 2.089
  [INFO] - Epoch 8/30 Step:: 80000 Loss: 1.093
  [INFO] - Epoch 8/30 Step:: 80500 Loss: 1.346
  [INFO] - Epoch 8/30 Step:: 81000 Loss: 2.575
  [INFO] - Epoch 8/30 Step:: 81500 Loss: 0.925
  [INFO] - Epoch 8/30 Step:: 82000 Loss: 1.969
  [INFO] --- Epoch 8 complete. Avg. Loss: 1.976  Time taken: 2558.564
  Validation Accuracy: 0.231
Saved:  m-fake-nettime-2021_05_16_19_08_43--num_classes-6-16052021-182303-epoch-7-val_acc-0.231-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 9/30 Step:: 82500 Loss: 5.582
  [INFO] - Epoch 9/30 Step:: 83000 Loss: 0.276
  [INFO] - Epoch 9/30 Step:: 83500 Loss: 1.087
  [INFO] - Epoch 9/30 Step:: 84000 Loss: 1.333
  [INFO] - Epoch 9/30 Step:: 84500 Loss: 1.327
  [INFO] - Epoch 9/30 Step:: 85000 Loss: 0.418
  [INFO] - Epoch 9/30 Step:: 85500 Loss: 1.629
  [INFO] - Epoch 9/30 Step:: 86000 Loss: 1.325
  [INFO] - Epoch 9/30 Step:: 86500 Loss: 2.077
  [INFO] - Epoch 9/30 Step:: 87000 Loss: 1.336
  [INFO] - Epoch 9/30 Step:: 87500 Loss: 1.730
  [INFO] - Epoch 9/30 Step:: 88000 Loss: 1.577
  [INFO] - Epoch 9/30 Step:: 88500 Loss: 0.760
  [INFO] - Epoch 9/30 Step:: 89000 Loss: 0.766
  [INFO] - Epoch 9/30 Step:: 89500 Loss: 2.034
  [INFO] - Epoch 9/30 Step:: 90000 Loss: 0.990
  [INFO] - Epoch 9/30 Step:: 90500 Loss: 0.827
  [INFO] - Epoch 9/30 Step:: 91000 Loss: 4.997
  [INFO] - Epoch 9/30 Step:: 91500 Loss: 0.678
  [INFO] - Epoch 9/30 Step:: 92000 Loss: 1.062
  [INFO] --- Epoch 9 complete. Avg. Loss: 1.969  Time taken: 2875.446
  Validation Accuracy: 0.232
Saved:  m-fake-nettime-2021_05_16_19_14_00--num_classes-6-16052021-182303-epoch-8-val_acc-0.232-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 10/30 Step:: 92500 Loss: 1.951
  [INFO] - Epoch 10/30 Step:: 93000 Loss: 1.072
  [INFO] - Epoch 10/30 Step:: 93500 Loss: 1.360
  [INFO] - Epoch 10/30 Step:: 94000 Loss: 0.738
  [INFO] - Epoch 10/30 Step:: 94500 Loss: 3.368
  [INFO] - Epoch 10/30 Step:: 95000 Loss: 0.950
  [INFO] - Epoch 10/30 Step:: 95500 Loss: 1.183
  [INFO] - Epoch 10/30 Step:: 96000 Loss: 1.952
  [INFO] - Epoch 10/30 Step:: 96500 Loss: 1.696
  [INFO] - Epoch 10/30 Step:: 97000 Loss: 1.118
  [INFO] - Epoch 10/30 Step:: 97500 Loss: 2.623
  [INFO] - Epoch 10/30 Step:: 98000 Loss: 3.678
  [INFO] - Epoch 10/30 Step:: 98500 Loss: 1.702
  [INFO] - Epoch 10/30 Step:: 99000 Loss: 3.656
  [INFO] - Epoch 10/30 Step:: 99500 Loss: 1.545
  [INFO] - Epoch 10/30 Step:: 100000 Loss: 0.884
  [INFO] - Epoch 10/30 Step:: 100500 Loss: 0.755
  [INFO] - Epoch 10/30 Step:: 101000 Loss: 2.235
  [INFO] - Epoch 10/30 Step:: 101500 Loss: 1.987
  [INFO] - Epoch 10/30 Step:: 102000 Loss: 2.962
  [INFO] - Epoch 10/30 Step:: 102500 Loss: 1.062
  [INFO] --- Epoch 10 complete. Avg. Loss: 1.946  Time taken: 3200.830
  Validation Accuracy: 0.221
Saved:  m-fake-nettime-2021_05_16_19_19_25--num_classes-6-16052021-182303-epoch-9-val_acc-0.221-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 11/30 Step:: 103000 Loss: 3.998
  [INFO] - Epoch 11/30 Step:: 103500 Loss: 1.390
  [INFO] - Epoch 11/30 Step:: 104000 Loss: 0.270
  [INFO] - Epoch 11/30 Step:: 104500 Loss: 0.343
  [INFO] - Epoch 11/30 Step:: 105000 Loss: 1.373
  [INFO] - Epoch 11/30 Step:: 105500 Loss: 3.127
  [INFO] - Epoch 11/30 Step:: 106000 Loss: 1.094
  [INFO] - Epoch 11/30 Step:: 106500 Loss: 1.295
  [INFO] - Epoch 11/30 Step:: 107000 Loss: 3.753
  [INFO] - Epoch 11/30 Step:: 107500 Loss: 1.763
  [INFO] - Epoch 11/30 Step:: 108000 Loss: 0.303
  [INFO] - Epoch 11/30 Step:: 108500 Loss: 2.484
  [INFO] - Epoch 11/30 Step:: 109000 Loss: 1.519
  [INFO] - Epoch 11/30 Step:: 109500 Loss: 1.617
  [INFO] - Epoch 11/30 Step:: 110000 Loss: 1.692
  [INFO] - Epoch 11/30 Step:: 110500 Loss: 2.587
  [INFO] - Epoch 11/30 Step:: 111000 Loss: 0.777
  [INFO] - Epoch 11/30 Step:: 111500 Loss: 1.790
  [INFO] - Epoch 11/30 Step:: 112000 Loss: 1.030
  [INFO] - Epoch 11/30 Step:: 112500 Loss: 1.631
  [INFO] --- Epoch 11 complete. Avg. Loss: 1.905  Time taken: 3534.666
  Validation Accuracy: 0.222
Saved:  m-fake-nettime-2021_05_16_19_24_59--num_classes-6-16052021-182303-epoch-10-val_acc-0.222-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 12/30 Step:: 113000 Loss: 2.087
  [INFO] - Epoch 12/30 Step:: 113500 Loss: 2.346
  [INFO] - Epoch 12/30 Step:: 114000 Loss: 1.086
  [INFO] - Epoch 12/30 Step:: 114500 Loss: 1.603
  [INFO] - Epoch 12/30 Step:: 115000 Loss: 5.059
  [INFO] - Epoch 12/30 Step:: 115500 Loss: 1.056
  [INFO] - Epoch 12/30 Step:: 116000 Loss: 3.049
  [INFO] - Epoch 12/30 Step:: 116500 Loss: 1.928
  [INFO] - Epoch 12/30 Step:: 117000 Loss: 1.038
  [INFO] - Epoch 12/30 Step:: 117500 Loss: 0.361
  [INFO] - Epoch 12/30 Step:: 118000 Loss: 2.706
  [INFO] - Epoch 12/30 Step:: 118500 Loss: 1.037
  [INFO] - Epoch 12/30 Step:: 119000 Loss: 1.523
  [INFO] - Epoch 12/30 Step:: 119500 Loss: 1.278
  [INFO] - Epoch 12/30 Step:: 120000 Loss: 1.018
  [INFO] - Epoch 12/30 Step:: 120500 Loss: 1.983
  [INFO] - Epoch 12/30 Step:: 121000 Loss: 3.639
  [INFO] - Epoch 12/30 Step:: 121500 Loss: 0.780
  [INFO] - Epoch 12/30 Step:: 122000 Loss: 0.373
  [INFO] - Epoch 12/30 Step:: 122500 Loss: 0.275
  [INFO] - Epoch 12/30 Step:: 123000 Loss: 0.392
  [INFO] --- Epoch 12 complete. Avg. Loss: 1.912  Time taken: 3880.974
  Validation Accuracy: 0.230
Saved:  m-fake-nettime-2021_05_16_19_30_46--num_classes-6-16052021-182303-epoch-11-val_acc-0.230-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 13/30 Step:: 123500 Loss: 2.160
  [INFO] - Epoch 13/30 Step:: 124000 Loss: 0.931
  [INFO] - Epoch 13/30 Step:: 124500 Loss: 2.295
  [INFO] - Epoch 13/30 Step:: 125000 Loss: 2.817
  [INFO] - Epoch 13/30 Step:: 125500 Loss: 0.213
  [INFO] - Epoch 13/30 Step:: 126000 Loss: 0.769
  [INFO] - Epoch 13/30 Step:: 126500 Loss: 0.403
  [INFO] - Epoch 13/30 Step:: 127000 Loss: 1.217
  [INFO] - Epoch 13/30 Step:: 127500 Loss: 0.694
  [INFO] - Epoch 13/30 Step:: 128000 Loss: 2.873
  [INFO] - Epoch 13/30 Step:: 128500 Loss: 0.288
  [INFO] - Epoch 13/30 Step:: 129000 Loss: 10.485
  [INFO] - Epoch 13/30 Step:: 129500 Loss: 1.889
  [INFO] - Epoch 13/30 Step:: 130000 Loss: 2.687
  [INFO] - Epoch 13/30 Step:: 130500 Loss: 1.472
  [INFO] - Epoch 13/30 Step:: 131000 Loss: 2.069
  [INFO] - Epoch 13/30 Step:: 131500 Loss: 1.103
  [INFO] - Epoch 13/30 Step:: 132000 Loss: 2.352
  [INFO] - Epoch 13/30 Step:: 132500 Loss: 2.249
  [INFO] - Epoch 13/30 Step:: 133000 Loss: 2.474
  [INFO] --- Epoch 13 complete. Avg. Loss: 1.869  Time taken: 4214.566
  Validation Accuracy: 0.232
Saved:  m-fake-nettime-2021_05_16_19_36_19--num_classes-6-16052021-182303-epoch-12-val_acc-0.232-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 14/30 Step:: 133500 Loss: 2.546
  [INFO] - Epoch 14/30 Step:: 134000 Loss: 3.751
  [INFO] - Epoch 14/30 Step:: 134500 Loss: 1.757
  [INFO] - Epoch 14/30 Step:: 135000 Loss: 4.223
  [INFO] - Epoch 14/30 Step:: 135500 Loss: 1.758
  [INFO] - Epoch 14/30 Step:: 136000 Loss: 1.268
  [INFO] - Epoch 14/30 Step:: 136500 Loss: 2.107
  [INFO] - Epoch 14/30 Step:: 137000 Loss: 18.245
  [INFO] - Epoch 14/30 Step:: 137500 Loss: 2.735
  [INFO] - Epoch 14/30 Step:: 138000 Loss: 3.608
  [INFO] - Epoch 14/30 Step:: 138500 Loss: 2.241
  [INFO] - Epoch 14/30 Step:: 139000 Loss: 1.620
  [INFO] - Epoch 14/30 Step:: 139500 Loss: 1.789
  [INFO] - Epoch 14/30 Step:: 140000 Loss: 0.728
  [INFO] - Epoch 14/30 Step:: 140500 Loss: 1.303
  [INFO] - Epoch 14/30 Step:: 141000 Loss: 1.963
  [INFO] - Epoch 14/30 Step:: 141500 Loss: 2.992
  [INFO] - Epoch 14/30 Step:: 142000 Loss: 2.256
  [INFO] - Epoch 14/30 Step:: 142500 Loss: 1.383
  [INFO] - Epoch 14/30 Step:: 143000 Loss: 5.828
  [INFO] - Epoch 14/30 Step:: 143500 Loss: 1.104
  [INFO] --- Epoch 14 complete. Avg. Loss: 1.892  Time taken: 4534.998
  Validation Accuracy: 0.236
Saved:  m-fake-nettime-2021_05_16_19_41_40--num_classes-6-16052021-182303-epoch-13-val_acc-0.236-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 15/30 Step:: 144000 Loss: 1.258
  [INFO] - Epoch 15/30 Step:: 144500 Loss: 2.271
  [INFO] - Epoch 15/30 Step:: 145000 Loss: 0.872
  [INFO] - Epoch 15/30 Step:: 145500 Loss: 0.544
  [INFO] - Epoch 15/30 Step:: 146000 Loss: 3.613
  [INFO] - Epoch 15/30 Step:: 146500 Loss: 2.102
  [INFO] - Epoch 15/30 Step:: 147000 Loss: 0.185
  [INFO] - Epoch 15/30 Step:: 147500 Loss: 0.810
  [INFO] - Epoch 15/30 Step:: 148000 Loss: 1.951
  [INFO] - Epoch 15/30 Step:: 148500 Loss: 3.308
  [INFO] - Epoch 15/30 Step:: 149000 Loss: 1.902
  [INFO] - Epoch 15/30 Step:: 149500 Loss: 2.072
  [INFO] - Epoch 15/30 Step:: 150000 Loss: 3.420
  [INFO] - Epoch 15/30 Step:: 150500 Loss: 1.148
  [INFO] - Epoch 15/30 Step:: 151000 Loss: 3.099
  [INFO] - Epoch 15/30 Step:: 151500 Loss: 3.408
  [INFO] - Epoch 15/30 Step:: 152000 Loss: 1.922
  [INFO] - Epoch 15/30 Step:: 152500 Loss: 1.130
  [INFO] - Epoch 15/30 Step:: 153000 Loss: 0.143
  [INFO] - Epoch 15/30 Step:: 153500 Loss: 2.305
  [INFO] - Epoch 15/30 Step:: 154000 Loss: 2.144
  [INFO] --- Epoch 15 complete. Avg. Loss: 1.844  Time taken: 4825.765
  Validation Accuracy: 0.249
Saved:  m-fake-nettime-2021_05_16_19_46_30--num_classes-6-16052021-182303-epoch-14-val_acc-0.249-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 16/30 Step:: 154500 Loss: 1.570
  [INFO] - Epoch 16/30 Step:: 155000 Loss: 2.571
  [INFO] - Epoch 16/30 Step:: 155500 Loss: 1.679
  [INFO] - Epoch 16/30 Step:: 156000 Loss: 2.539
  [INFO] - Epoch 16/30 Step:: 156500 Loss: 2.704
  [INFO] - Epoch 16/30 Step:: 157000 Loss: 1.233
  [INFO] - Epoch 16/30 Step:: 157500 Loss: 4.342
  [INFO] - Epoch 16/30 Step:: 158000 Loss: 0.020
  [INFO] - Epoch 16/30 Step:: 158500 Loss: 2.806
  [INFO] - Epoch 16/30 Step:: 159000 Loss: 1.660
  [INFO] - Epoch 16/30 Step:: 159500 Loss: 2.286
  [INFO] - Epoch 16/30 Step:: 160000 Loss: 3.310
  [INFO] - Epoch 16/30 Step:: 160500 Loss: 1.667
  [INFO] - Epoch 16/30 Step:: 161000 Loss: 2.946
  [INFO] - Epoch 16/30 Step:: 161500 Loss: 1.884
  [INFO] - Epoch 16/30 Step:: 162000 Loss: 3.097
  [INFO] - Epoch 16/30 Step:: 162500 Loss: 3.170
  [INFO] - Epoch 16/30 Step:: 163000 Loss: 3.274
  [INFO] - Epoch 16/30 Step:: 163500 Loss: 0.631
  [INFO] - Epoch 16/30 Step:: 164000 Loss: 0.518
  [INFO] --- Epoch 16 complete. Avg. Loss: 1.818  Time taken: 5165.411
  Validation Accuracy: 0.227
Saved:  m-fake-nettime-2021_05_16_19_52_10--num_classes-6-16052021-182303-epoch-15-val_acc-0.227-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 17/30 Step:: 164500 Loss: 0.768
  [INFO] - Epoch 17/30 Step:: 165000 Loss: 2.428
  [INFO] - Epoch 17/30 Step:: 165500 Loss: 0.799
  [INFO] - Epoch 17/30 Step:: 166000 Loss: 1.950
  [INFO] - Epoch 17/30 Step:: 166500 Loss: 1.535
  [INFO] - Epoch 17/30 Step:: 167000 Loss: 1.667
  [INFO] - Epoch 17/30 Step:: 167500 Loss: 1.600
  [INFO] - Epoch 17/30 Step:: 168000 Loss: 2.267
  [INFO] - Epoch 17/30 Step:: 168500 Loss: 1.590
  [INFO] - Epoch 17/30 Step:: 169000 Loss: 2.681
  [INFO] - Epoch 17/30 Step:: 169500 Loss: 1.912
  [INFO] - Epoch 17/30 Step:: 170000 Loss: 1.071
  [INFO] - Epoch 17/30 Step:: 170500 Loss: 2.956
  [INFO] - Epoch 17/30 Step:: 171000 Loss: 1.835
  [INFO] - Epoch 17/30 Step:: 171500 Loss: 1.604
  [INFO] - Epoch 17/30 Step:: 172000 Loss: 1.268
  [INFO] - Epoch 17/30 Step:: 172500 Loss: 2.284
  [INFO] - Epoch 17/30 Step:: 173000 Loss: 3.711
  [INFO] - Epoch 17/30 Step:: 173500 Loss: 1.261
  [INFO] - Epoch 17/30 Step:: 174000 Loss: 0.802
  [INFO] - Epoch 17/30 Step:: 174500 Loss: 2.341
  [INFO] --- Epoch 17 complete. Avg. Loss: 1.815  Time taken: 5460.116
  Validation Accuracy: 0.221
Saved:  m-fake-nettime-2021_05_16_19_57_05--num_classes-6-16052021-182303-epoch-16-val_acc-0.221-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 18/30 Step:: 175000 Loss: 1.444
  [INFO] - Epoch 18/30 Step:: 175500 Loss: 2.461
  [INFO] - Epoch 18/30 Step:: 176000 Loss: 1.695
  [INFO] - Epoch 18/30 Step:: 176500 Loss: 0.342
  [INFO] - Epoch 18/30 Step:: 177000 Loss: 7.566
  [INFO] - Epoch 18/30 Step:: 177500 Loss: 2.465
  [INFO] - Epoch 18/30 Step:: 178000 Loss: 0.722
  [INFO] - Epoch 18/30 Step:: 178500 Loss: 1.926
  [INFO] - Epoch 18/30 Step:: 179000 Loss: 5.290
  [INFO] - Epoch 18/30 Step:: 179500 Loss: 0.387
  [INFO] - Epoch 18/30 Step:: 180000 Loss: 1.816
  [INFO] - Epoch 18/30 Step:: 180500 Loss: 2.705
  [INFO] - Epoch 18/30 Step:: 181000 Loss: 0.943
  [INFO] - Epoch 18/30 Step:: 181500 Loss: 3.392
  [INFO] - Epoch 18/30 Step:: 182000 Loss: 1.556
  [INFO] - Epoch 18/30 Step:: 182500 Loss: 1.024
  [INFO] - Epoch 18/30 Step:: 183000 Loss: 2.244
  [INFO] - Epoch 18/30 Step:: 183500 Loss: 1.798
  [INFO] - Epoch 18/30 Step:: 184000 Loss: 0.688
  [INFO] - Epoch 18/30 Step:: 184500 Loss: 1.240
  [INFO] --- Epoch 18 complete. Avg. Loss: 1.807  Time taken: 5822.386
  Validation Accuracy: 0.236
Saved:  m-fake-nettime-2021_05_16_20_03_07--num_classes-6-16052021-182303-epoch-17-val_acc-0.236-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 19/30 Step:: 185000 Loss: 1.510
  [INFO] - Epoch 19/30 Step:: 185500 Loss: 1.445
  [INFO] - Epoch 19/30 Step:: 186000 Loss: 1.756
  [INFO] - Epoch 19/30 Step:: 186500 Loss: 2.892
  [INFO] - Epoch 19/30 Step:: 187000 Loss: 2.470
  [INFO] - Epoch 19/30 Step:: 187500 Loss: 1.747
  [INFO] - Epoch 19/30 Step:: 188000 Loss: 3.572
  [INFO] - Epoch 19/30 Step:: 188500 Loss: 1.161
  [INFO] - Epoch 19/30 Step:: 189000 Loss: 0.517
  [INFO] - Epoch 19/30 Step:: 189500 Loss: 3.160
  [INFO] - Epoch 19/30 Step:: 190000 Loss: 0.393
  [INFO] - Epoch 19/30 Step:: 190500 Loss: 1.238
  [INFO] - Epoch 19/30 Step:: 191000 Loss: 0.749
  [INFO] - Epoch 19/30 Step:: 191500 Loss: 2.120
  [INFO] - Epoch 19/30 Step:: 192000 Loss: 1.784
  [INFO] - Epoch 19/30 Step:: 192500 Loss: 1.290
  [INFO] - Epoch 19/30 Step:: 193000 Loss: 2.720
  [INFO] - Epoch 19/30 Step:: 193500 Loss: 1.701
  [INFO] - Epoch 19/30 Step:: 194000 Loss: 3.254
  [INFO] - Epoch 19/30 Step:: 194500 Loss: 0.597
  [INFO] - Epoch 19/30 Step:: 195000 Loss: 0.094
  [INFO] --- Epoch 19 complete. Avg. Loss: 1.782  Time taken: 6142.818
  Validation Accuracy: 0.230
Saved:  m-fake-nettime-2021_05_16_20_08_27--num_classes-6-16052021-182303-epoch-18-val_acc-0.230-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 20/30 Step:: 195500 Loss: 0.684
  [INFO] - Epoch 20/30 Step:: 196000 Loss: 1.146
  [INFO] - Epoch 20/30 Step:: 196500 Loss: 1.696
  [INFO] - Epoch 20/30 Step:: 197000 Loss: 0.521
  [INFO] - Epoch 20/30 Step:: 197500 Loss: 2.440
  [INFO] - Epoch 20/30 Step:: 198000 Loss: 2.826
  [INFO] - Epoch 20/30 Step:: 198500 Loss: 1.318
  [INFO] - Epoch 20/30 Step:: 199000 Loss: 1.796
  [INFO] - Epoch 20/30 Step:: 199500 Loss: 1.532
  [INFO] - Epoch 20/30 Step:: 200000 Loss: 1.437
  [INFO] - Epoch 20/30 Step:: 200500 Loss: 0.261
  [INFO] - Epoch 20/30 Step:: 201000 Loss: 1.390
  [INFO] - Epoch 20/30 Step:: 201500 Loss: 4.575
  [INFO] - Epoch 20/30 Step:: 202000 Loss: 2.446
  [INFO] - Epoch 20/30 Step:: 202500 Loss: 0.641
  [INFO] - Epoch 20/30 Step:: 203000 Loss: 0.177
  [INFO] - Epoch 20/30 Step:: 203500 Loss: 0.945
  [INFO] - Epoch 20/30 Step:: 204000 Loss: 1.110
  [INFO] - Epoch 20/30 Step:: 204500 Loss: 16.585
  [INFO] - Epoch 20/30 Step:: 205000 Loss: 3.767
  [INFO] --- Epoch 20 complete. Avg. Loss: 1.765  Time taken: 6471.974
  Validation Accuracy: 0.246
Saved:  m-fake-nettime-2021_05_16_20_13_57--num_classes-6-16052021-182303-epoch-19-val_acc-0.246-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 21/30 Step:: 205500 Loss: 0.988
  [INFO] - Epoch 21/30 Step:: 206000 Loss: 2.501
  [INFO] - Epoch 21/30 Step:: 206500 Loss: 1.905
  [INFO] - Epoch 21/30 Step:: 207000 Loss: 1.062
  [INFO] - Epoch 21/30 Step:: 207500 Loss: 2.036
  [INFO] - Epoch 21/30 Step:: 208000 Loss: 0.308
  [INFO] - Epoch 21/30 Step:: 208500 Loss: 1.133
  [INFO] - Epoch 21/30 Step:: 209000 Loss: 0.885
  [INFO] - Epoch 21/30 Step:: 209500 Loss: 2.487
  [INFO] - Epoch 21/30 Step:: 210000 Loss: 1.734
  [INFO] - Epoch 21/30 Step:: 210500 Loss: 2.591
  [INFO] - Epoch 21/30 Step:: 211000 Loss: 3.349
  [INFO] - Epoch 21/30 Step:: 211500 Loss: 1.374
  [INFO] - Epoch 21/30 Step:: 212000 Loss: 0.953
  [INFO] - Epoch 21/30 Step:: 212500 Loss: 3.219
  [INFO] - Epoch 21/30 Step:: 213000 Loss: 1.529
  [INFO] - Epoch 21/30 Step:: 213500 Loss: 0.437
  [INFO] - Epoch 21/30 Step:: 214000 Loss: 3.108
  [INFO] - Epoch 21/30 Step:: 214500 Loss: 1.336
  [INFO] - Epoch 21/30 Step:: 215000 Loss: 1.335
  [INFO] - Epoch 21/30 Step:: 215500 Loss: 3.402
  [INFO] --- Epoch 21 complete. Avg. Loss: 1.744  Time taken: 6788.220
  Validation Accuracy: 0.246
Saved:  m-fake-nettime-2021_05_16_20_19_13--num_classes-6-16052021-182303-epoch-20-val_acc-0.246-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 22/30 Step:: 216000 Loss: 0.435
  [INFO] - Epoch 22/30 Step:: 216500 Loss: 2.431
  [INFO] - Epoch 22/30 Step:: 217000 Loss: 2.141
  [INFO] - Epoch 22/30 Step:: 217500 Loss: 1.251
  [INFO] - Epoch 22/30 Step:: 218000 Loss: 1.627
  [INFO] - Epoch 22/30 Step:: 218500 Loss: 3.525
  [INFO] - Epoch 22/30 Step:: 219000 Loss: 0.897
  [INFO] - Epoch 22/30 Step:: 219500 Loss: 0.729
  [INFO] - Epoch 22/30 Step:: 220000 Loss: 1.661
  [INFO] - Epoch 22/30 Step:: 220500 Loss: 2.381
  [INFO] - Epoch 22/30 Step:: 221000 Loss: 1.978
  [INFO] - Epoch 22/30 Step:: 221500 Loss: 1.294
  [INFO] - Epoch 22/30 Step:: 222000 Loss: 3.191
  [INFO] - Epoch 22/30 Step:: 222500 Loss: 3.352
  [INFO] - Epoch 22/30 Step:: 223000 Loss: 3.051
  [INFO] - Epoch 22/30 Step:: 223500 Loss: 1.984
  [INFO] - Epoch 22/30 Step:: 224000 Loss: 0.038
  [INFO] - Epoch 22/30 Step:: 224500 Loss: 1.861
  [INFO] - Epoch 22/30 Step:: 225000 Loss: 2.090
  [INFO] - Epoch 22/30 Step:: 225500 Loss: 0.989
  [INFO] --- Epoch 22 complete. Avg. Loss: 1.728  Time taken: 7130.641
  Validation Accuracy: 0.205
Saved:  m-fake-nettime-2021_05_16_20_24_55--num_classes-6-16052021-182303-epoch-21-val_acc-0.205-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 23/30 Step:: 226000 Loss: 3.287
  [INFO] - Epoch 23/30 Step:: 226500 Loss: 1.345
  [INFO] - Epoch 23/30 Step:: 227000 Loss: 1.643
  [INFO] - Epoch 23/30 Step:: 227500 Loss: 0.390
  [INFO] - Epoch 23/30 Step:: 228000 Loss: 1.021
  [INFO] - Epoch 23/30 Step:: 228500 Loss: 2.395
  [INFO] - Epoch 23/30 Step:: 229000 Loss: 0.881
  [INFO] - Epoch 23/30 Step:: 229500 Loss: 1.599
  [INFO] - Epoch 23/30 Step:: 230000 Loss: 1.186
  [INFO] - Epoch 23/30 Step:: 230500 Loss: 1.757
  [INFO] - Epoch 23/30 Step:: 231000 Loss: 0.423
  [INFO] - Epoch 23/30 Step:: 231500 Loss: 1.200
  [INFO] - Epoch 23/30 Step:: 232000 Loss: 0.800
  [INFO] - Epoch 23/30 Step:: 232500 Loss: 0.924
  [INFO] - Epoch 23/30 Step:: 233000 Loss: 2.325
  [INFO] - Epoch 23/30 Step:: 233500 Loss: 1.768
  [INFO] - Epoch 23/30 Step:: 234000 Loss: 1.212
  [INFO] - Epoch 23/30 Step:: 234500 Loss: 1.696
  [INFO] - Epoch 23/30 Step:: 235000 Loss: 3.242
  [INFO] - Epoch 23/30 Step:: 235500 Loss: 1.381
  [INFO] - Epoch 23/30 Step:: 236000 Loss: 1.341
  [INFO] --- Epoch 23 complete. Avg. Loss: 1.705  Time taken: 7470.436
  Validation Accuracy: 0.231
Saved:  m-fake-nettime-2021_05_16_20_30_35--num_classes-6-16052021-182303-epoch-22-val_acc-0.231-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 24/30 Step:: 236500 Loss: 1.818
  [INFO] - Epoch 24/30 Step:: 237000 Loss: 0.904
  [INFO] - Epoch 24/30 Step:: 237500 Loss: 2.591
  [INFO] - Epoch 24/30 Step:: 238000 Loss: 0.664
  [INFO] - Epoch 24/30 Step:: 238500 Loss: 0.984
  [INFO] - Epoch 24/30 Step:: 239000 Loss: 0.043
  [INFO] - Epoch 24/30 Step:: 239500 Loss: 1.962
  [INFO] - Epoch 24/30 Step:: 240000 Loss: 1.848
  [INFO] - Epoch 24/30 Step:: 240500 Loss: 1.559
  [INFO] - Epoch 24/30 Step:: 241000 Loss: 1.803
  [INFO] - Epoch 24/30 Step:: 241500 Loss: 1.138
  [INFO] - Epoch 24/30 Step:: 242000 Loss: 3.064
  [INFO] - Epoch 24/30 Step:: 242500 Loss: 2.303
  [INFO] - Epoch 24/30 Step:: 243000 Loss: 3.181
  [INFO] - Epoch 24/30 Step:: 243500 Loss: 0.068
  [INFO] - Epoch 24/30 Step:: 244000 Loss: 1.730
  [INFO] - Epoch 24/30 Step:: 244500 Loss: 1.575
  [INFO] - Epoch 24/30 Step:: 245000 Loss: 1.690
  [INFO] - Epoch 24/30 Step:: 245500 Loss: 0.794
  [INFO] - Epoch 24/30 Step:: 246000 Loss: 1.531
  [INFO] --- Epoch 24 complete. Avg. Loss: 1.701  Time taken: 7798.533
  Validation Accuracy: 0.217
Saved:  m-fake-nettime-2021_05_16_20_36_03--num_classes-6-16052021-182303-epoch-23-val_acc-0.217-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 25/30 Step:: 246500 Loss: 0.931
  [INFO] - Epoch 25/30 Step:: 247000 Loss: 1.747
  [INFO] - Epoch 25/30 Step:: 247500 Loss: 1.593
  [INFO] - Epoch 25/30 Step:: 248000 Loss: 3.275
  [INFO] - Epoch 25/30 Step:: 248500 Loss: 2.026
  [INFO] - Epoch 25/30 Step:: 249000 Loss: 2.499
  [INFO] - Epoch 25/30 Step:: 249500 Loss: 0.005
  [INFO] - Epoch 25/30 Step:: 250000 Loss: 0.931
  [INFO] - Epoch 25/30 Step:: 250500 Loss: 3.141
  [INFO] - Epoch 25/30 Step:: 251000 Loss: 0.271
  [INFO] - Epoch 25/30 Step:: 251500 Loss: 1.475
  [INFO] - Epoch 25/30 Step:: 252000 Loss: 2.273
  [INFO] - Epoch 25/30 Step:: 252500 Loss: 0.424
  [INFO] - Epoch 25/30 Step:: 253000 Loss: 0.108
  [INFO] - Epoch 25/30 Step:: 253500 Loss: 2.035
  [INFO] - Epoch 25/30 Step:: 254000 Loss: 2.905
  [INFO] - Epoch 25/30 Step:: 254500 Loss: 0.725
  [INFO] - Epoch 25/30 Step:: 255000 Loss: 1.853
  [INFO] - Epoch 25/30 Step:: 255500 Loss: 1.441
  [INFO] - Epoch 25/30 Step:: 256000 Loss: 1.343
  [INFO] - Epoch 25/30 Step:: 256500 Loss: 0.455
  [INFO] --- Epoch 25 complete. Avg. Loss: 1.678  Time taken: 8113.705
  Validation Accuracy: 0.259
Saved:  m-fake-nettime-2021_05_16_20_41_18--num_classes-6-16052021-182303-epoch-24-val_acc-0.259-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 26/30 Step:: 257000 Loss: 2.545
  [INFO] - Epoch 26/30 Step:: 257500 Loss: 0.726
  [INFO] - Epoch 26/30 Step:: 258000 Loss: 0.491
  [INFO] - Epoch 26/30 Step:: 258500 Loss: 0.437
  [INFO] - Epoch 26/30 Step:: 259000 Loss: 1.867
  [INFO] - Epoch 26/30 Step:: 259500 Loss: 10.377
  [INFO] - Epoch 26/30 Step:: 260000 Loss: 0.543
  [INFO] - Epoch 26/30 Step:: 260500 Loss: 0.941
  [INFO] - Epoch 26/30 Step:: 261000 Loss: 1.466
  [INFO] - Epoch 26/30 Step:: 261500 Loss: 2.366
  [INFO] - Epoch 26/30 Step:: 262000 Loss: 0.075
  [INFO] - Epoch 26/30 Step:: 262500 Loss: 1.945
  [INFO] - Epoch 26/30 Step:: 263000 Loss: 0.393
  [INFO] - Epoch 26/30 Step:: 263500 Loss: 1.711
  [INFO] - Epoch 26/30 Step:: 264000 Loss: 1.153
  [INFO] - Epoch 26/30 Step:: 264500 Loss: 1.525
  [INFO] - Epoch 26/30 Step:: 265000 Loss: 1.425
  [INFO] - Epoch 26/30 Step:: 265500 Loss: 0.449
  [INFO] - Epoch 26/30 Step:: 266000 Loss: 1.840
  [INFO] - Epoch 26/30 Step:: 266500 Loss: 0.014
  [INFO] --- Epoch 26 complete. Avg. Loss: 1.681  Time taken: 8443.481
  Validation Accuracy: 0.238
Saved:  m-fake-nettime-2021_05_16_20_46_48--num_classes-6-16052021-182303-epoch-25-val_acc-0.238-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 27/30 Step:: 267000 Loss: 3.549
  [INFO] - Epoch 27/30 Step:: 267500 Loss: 2.037
  [INFO] - Epoch 27/30 Step:: 268000 Loss: 1.514
  [INFO] - Epoch 27/30 Step:: 268500 Loss: 2.704
  [INFO] - Epoch 27/30 Step:: 269000 Loss: 1.161
  [INFO] - Epoch 27/30 Step:: 269500 Loss: 1.554
  [INFO] - Epoch 27/30 Step:: 270000 Loss: 1.094
  [INFO] - Epoch 27/30 Step:: 270500 Loss: 1.211
  [INFO] - Epoch 27/30 Step:: 271000 Loss: 0.126
  [INFO] - Epoch 27/30 Step:: 271500 Loss: 0.761
  [INFO] - Epoch 27/30 Step:: 272000 Loss: 1.706
  [INFO] - Epoch 27/30 Step:: 272500 Loss: 4.374
  [INFO] - Epoch 27/30 Step:: 273000 Loss: 1.792
  [INFO] - Epoch 27/30 Step:: 273500 Loss: 1.238
  [INFO] - Epoch 27/30 Step:: 274000 Loss: 1.266
  [INFO] - Epoch 27/30 Step:: 274500 Loss: 1.374
  [INFO] - Epoch 27/30 Step:: 275000 Loss: 2.658
  [INFO] - Epoch 27/30 Step:: 275500 Loss: 1.712
  [INFO] - Epoch 27/30 Step:: 276000 Loss: 1.882
  [INFO] - Epoch 27/30 Step:: 276500 Loss: 0.261
  [INFO] - Epoch 27/30 Step:: 277000 Loss: 1.085
  [INFO] --- Epoch 27 complete. Avg. Loss: 1.684  Time taken: 8740.262
  Validation Accuracy: 0.210
Saved:  m-fake-nettime-2021_05_16_20_51_45--num_classes-6-16052021-182303-epoch-26-val_acc-0.210-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 28/30 Step:: 277500 Loss: 2.955
  [INFO] - Epoch 28/30 Step:: 278000 Loss: 0.621
  [INFO] - Epoch 28/30 Step:: 278500 Loss: 1.927
  [INFO] - Epoch 28/30 Step:: 279000 Loss: 0.733
  [INFO] - Epoch 28/30 Step:: 279500 Loss: 1.218
  [INFO] - Epoch 28/30 Step:: 280000 Loss: 0.798
  [INFO] - Epoch 28/30 Step:: 280500 Loss: 0.433
  [INFO] - Epoch 28/30 Step:: 281000 Loss: 1.061
  [INFO] - Epoch 28/30 Step:: 281500 Loss: 1.864
  [INFO] - Epoch 28/30 Step:: 282000 Loss: 1.509
  [INFO] - Epoch 28/30 Step:: 282500 Loss: 0.715
  [INFO] - Epoch 28/30 Step:: 283000 Loss: 1.637
  [INFO] - Epoch 28/30 Step:: 283500 Loss: 1.750
  [INFO] - Epoch 28/30 Step:: 284000 Loss: 0.225
  [INFO] - Epoch 28/30 Step:: 284500 Loss: 1.166
  [INFO] - Epoch 28/30 Step:: 285000 Loss: 1.055
  [INFO] - Epoch 28/30 Step:: 285500 Loss: 1.035
  [INFO] - Epoch 28/30 Step:: 286000 Loss: 2.758
  [INFO] - Epoch 28/30 Step:: 286500 Loss: 0.500
  [INFO] - Epoch 28/30 Step:: 287000 Loss: 1.559
  [INFO] - Epoch 28/30 Step:: 287500 Loss: 0.734
  [INFO] --- Epoch 28 complete. Avg. Loss: 1.645  Time taken: 9016.739
  Validation Accuracy: 0.242
Saved:  m-fake-nettime-2021_05_16_20_56_21--num_classes-6-16052021-182303-epoch-27-val_acc-0.242-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 29/30 Step:: 288000 Loss: 3.264
  [INFO] - Epoch 29/30 Step:: 288500 Loss: 0.753
  [INFO] - Epoch 29/30 Step:: 289000 Loss: 0.226
  [INFO] - Epoch 29/30 Step:: 289500 Loss: 3.141
  [INFO] - Epoch 29/30 Step:: 290000 Loss: 4.717
  [INFO] - Epoch 29/30 Step:: 290500 Loss: 1.670
  [INFO] - Epoch 29/30 Step:: 291000 Loss: 0.613
  [INFO] - Epoch 29/30 Step:: 291500 Loss: 0.156
  [INFO] - Epoch 29/30 Step:: 292000 Loss: 1.021
  [INFO] - Epoch 29/30 Step:: 292500 Loss: 3.988
  [INFO] - Epoch 29/30 Step:: 293000 Loss: 2.095
  [INFO] - Epoch 29/30 Step:: 293500 Loss: 1.625
  [INFO] - Epoch 29/30 Step:: 294000 Loss: 0.070
  [INFO] - Epoch 29/30 Step:: 294500 Loss: 2.809
  [INFO] - Epoch 29/30 Step:: 295000 Loss: 0.964
  [INFO] - Epoch 29/30 Step:: 295500 Loss: 1.968
  [INFO] - Epoch 29/30 Step:: 296000 Loss: 2.245
  [INFO] - Epoch 29/30 Step:: 296500 Loss: 1.356
  [INFO] - Epoch 29/30 Step:: 297000 Loss: 1.217
  [INFO] - Epoch 29/30 Step:: 297500 Loss: 2.659
  [INFO] --- Epoch 29 complete. Avg. Loss: 1.640  Time taken: 9361.358
  Validation Accuracy: 0.242
Saved:  m-fake-nettime-2021_05_16_21_02_06--num_classes-6-16052021-182303-epoch-28-val_acc-0.242-new_feats-wiki_bert_feat.pth.tar
  [INFO] - Epoch 30/30 Step:: 298000 Loss: 1.037
  [INFO] - Epoch 30/30 Step:: 298500 Loss: 2.860
  [INFO] - Epoch 30/30 Step:: 299000 Loss: 2.214
  [INFO] - Epoch 30/30 Step:: 299500 Loss: 2.343
  [INFO] - Epoch 30/30 Step:: 300000 Loss: 0.905
  [INFO] - Epoch 30/30 Step:: 300500 Loss: 2.814
  [INFO] - Epoch 30/30 Step:: 301000 Loss: 0.891
  [INFO] - Epoch 30/30 Step:: 301500 Loss: 0.696
  [INFO] - Epoch 30/30 Step:: 302000 Loss: 2.496
  [INFO] - Epoch 30/30 Step:: 302500 Loss: 0.683
  [INFO] - Epoch 30/30 Step:: 303000 Loss: 1.085
  [INFO] - Epoch 30/30 Step:: 303500 Loss: 0.446
  [INFO] - Epoch 30/30 Step:: 304000 Loss: 1.433
  [INFO] - Epoch 30/30 Step:: 304500 Loss: 1.049
  [INFO] - Epoch 30/30 Step:: 305000 Loss: 2.268
  [INFO] - Epoch 30/30 Step:: 305500 Loss: 0.879
  [INFO] - Epoch 30/30 Step:: 306000 Loss: 2.620
  [INFO] - Epoch 30/30 Step:: 306500 Loss: 0.465
  [INFO] - Epoch 30/30 Step:: 307000 Loss: 0.641
  [INFO] - Epoch 30/30 Step:: 307500 Loss: 0.023
  [INFO] - Epoch 30/30 Step:: 308000 Loss: 1.461
  [INFO] --- Epoch 30 complete. Avg. Loss: 1.631  Time taken: 9662.346
  Validation Accuracy: 0.220
Saved:  m-fake-nettime-2021_05_16_21_07_07--num_classes-6-16052021-182303-epoch-29-val_acc-0.220-new_feats-wiki_bert_feat.pth.tar
PATHMODEL could not be loaded: None
Traceback (most recent call last):
  File "main.py", line 260, in <module>
    driver('train2.tsv', 'val2.tsv', 'test2.tsv', 'predictions.txt', dataset_name, mode, features, pathModel, hyper, feat_list=feat_list)
  File "main.py", line 170, in driver
    test_acc = test(test_samples, output_file, model, num_classes, use_cuda, feat_list=feat_list)
UnboundLocalError: local variable 'test_samples' referenced before assignment
